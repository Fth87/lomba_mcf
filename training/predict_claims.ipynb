{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35aaf33a",
   "metadata": {},
   "source": [
    "# Prediksi Klaim Asuransi dengan Chronos-2\n",
    "Forecasting frekuensi klaim, total klaim, dan severitas untuk 5 bulan ke depan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1743a604",
   "metadata": {},
   "source": [
    "## Tahap 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67f42ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data/lomba/mcf/pengerjaan/.venv/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The StatsForecast module could not be imported. To enable support for the AutoARIMA, AutoETS and Croston models, please consider installing it.\n",
      "The `XGBoost` module could not be imported. To enable XGBoost support in Darts, follow the detailed instructions in the installation guide: https://github.com/unit8co/darts/blob/master/INSTALL.md\n",
      "The `XGBoost` module could not be imported. To enable XGBoost support in Darts, follow the detailed instructions in the installation guide: https://github.com/unit8co/darts/blob/master/INSTALL.md\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from darts import TimeSeries, concatenate\n",
    "from darts.models import Chronos2Model\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "import warnings\n",
    "import os\n",
    "import torch\n",
    "from mlforecast import MLForecast\n",
    "# from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2244f6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU Name: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n",
      "GPU Memory: 3.95 GB\n",
      "CUDA Version: 13.1\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"GPU not available. Training will use CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccd996d",
   "metadata": {},
   "source": [
    "## Tahap 2: Load and Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7115d391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Data Polis shape: (4096, 6)\n",
      "Data Klaim shape: (4627, 13)\n",
      "\n",
      "Merging data...\n",
      "Merged data shape: (4627, 18)\n"
     ]
    }
   ],
   "source": [
    "# Load Datasets\n",
    "print(\"Loading datasets...\")\n",
    "df_polis = pd.read_csv(\"../dataset/Data_Polis.csv\")\n",
    "df_klaim = pd.read_csv(\"../dataset/Data_Klaim.csv\")\n",
    "\n",
    "print(f\"Data Polis shape: {df_polis.shape}\")\n",
    "print(f\"Data Klaim shape: {df_klaim.shape}\")\n",
    "\n",
    "# Identify Keys & Merge\n",
    "print(\"\\nMerging data...\")\n",
    "df = pd.merge(df_klaim, df_polis, on=\"Nomor Polis\", how=\"left\")\n",
    "print(f\"Merged data shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bf0d88",
   "metadata": {},
   "source": [
    "## Tahap 3: Clean Date Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36d7ea6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning dates...\n",
      "Date conversion completed\n"
     ]
    }
   ],
   "source": [
    "# Data Cleaning (Dates)\n",
    "print(\"Cleaning dates...\")\n",
    "date_columns = [\"Tanggal Pembayaran Klaim\", \"Tanggal Pasien Masuk RS\", \"Tanggal Pasien Keluar RS\", \"Tanggal Efektif Polis\"]\n",
    "for col in date_columns:\n",
    "    df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "df[\"Tanggal Lahir\"] = pd.to_datetime(df[\"Tanggal Lahir\"], format=\"%Y%m%d\", errors='coerce')\n",
    "\n",
    "print(\"Date conversion completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e4091c",
   "metadata": {},
   "source": [
    "## Tahap 4: Filter Data by Date Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc98e129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Claims after filtering: 4627\n",
      "Date range: 2024-01-01 to 2025-07-31\n"
     ]
    }
   ],
   "source": [
    "# Analysis Population (Filter Date Range)\n",
    "start_date = \"2024-01-01\"\n",
    "end_date = \"2025-07-31\"\n",
    "df_filtered = df[(df[\"Tanggal Pasien Masuk RS\"] >= start_date) & \n",
    "                 (df[\"Tanggal Pasien Masuk RS\"] <= end_date)].copy()\n",
    "\n",
    "print(f\"Total Claims after filtering: {len(df_filtered)}\")\n",
    "print(f\"Date range: {start_date} to {end_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5fed10",
   "metadata": {},
   "source": [
    "## Tahap 5: Feature Engineering - Age and Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6e9cbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age and Region features created\n",
      "\n",
      "Age statistics:\n",
      "count    4627.000000\n",
      "mean       59.719257\n",
      "std        12.569963\n",
      "min         8.000000\n",
      "25%        52.000000\n",
      "50%        60.000000\n",
      "75%        69.000000\n",
      "max        91.000000\n",
      "Name: Usia, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Profil Risiko: Usia & Wilayah\n",
    "reference_date = pd.to_datetime(\"2025-08-01\")\n",
    "df_filtered[\"Usia\"] = (reference_date - df_filtered[\"Tanggal Lahir\"]).dt.days // 365\n",
    "df_filtered[\"Wilayah\"] = df_filtered[\"Plan Code\"].map({\"M-001\": \"Wilayah A\", \"M-002\": \"Wilayah B\", \"M-003\": \"Wilayah C\"})\n",
    "\n",
    "print(\"Age and Region features created\")\n",
    "print(f\"\\nAge statistics:\\n{df_filtered['Usia'].describe()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f8e76a",
   "metadata": {},
   "source": [
    "## Tahap 6: Feature Engineering - ICD Grouping and Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab65618c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICD Grouping and Duration features created\n",
      "\n",
      "Duration of stay statistics:\n",
      "count    4627.000000\n",
      "mean        1.264102\n",
      "std         2.930572\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         1.000000\n",
      "max        54.000000\n",
      "Name: Durasi_Rawat, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Kategorisasi Medis: ICD Grouping\n",
    "df_filtered[\"ICD_Group\"] = df_filtered[\"ICD Diagnosis\"].astype(str).str.split('.').str[0]\n",
    "\n",
    "# Durasi dan Metode\n",
    "df_filtered[\"Durasi_Rawat\"] = (df_filtered[\"Tanggal Pasien Keluar RS\"] - df_filtered[\"Tanggal Pasien Masuk RS\"]).dt.days\n",
    "df_filtered[\"Durasi_Rawat\"] = df_filtered[\"Durasi_Rawat\"].clip(lower=0)\n",
    "\n",
    "print(\"ICD Grouping and Duration features created\")\n",
    "print(f\"\\nDuration of stay statistics:\\n{df_filtered['Durasi_Rawat'].describe()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8917b81a",
   "metadata": {},
   "source": [
    "## Tahap 7: Aggregate Historical Metrics by Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c5d60fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historical Metrics:\n",
      "      Bulan  Frequency   Total_Claim      Severity   Bulan_Ts\n",
      "0   2024-01        302  2.026098e+10  6.708934e+07 2024-01-01\n",
      "1   2024-02        208  1.385965e+10  6.663291e+07 2024-02-01\n",
      "2   2024-03        278  1.431126e+10  5.147935e+07 2024-03-01\n",
      "3   2024-04        239  1.144106e+10  4.787056e+07 2024-04-01\n",
      "4   2024-05        263  1.221146e+10  4.643141e+07 2024-05-01\n",
      "5   2024-06        225  1.212517e+10  5.388963e+07 2024-06-01\n",
      "6   2024-07        257  1.497052e+10  5.825104e+07 2024-07-01\n",
      "7   2024-08        228  1.351294e+10  5.926726e+07 2024-08-01\n",
      "8   2024-09        208  1.226412e+10  5.896211e+07 2024-09-01\n",
      "9   2024-10        274  1.268117e+10  4.628163e+07 2024-10-01\n",
      "10  2024-11        270  1.373306e+10  5.086318e+07 2024-11-01\n",
      "11  2024-12        238  1.201391e+10  5.047861e+07 2024-12-01\n",
      "12  2025-01        216  9.610380e+09  4.449250e+07 2025-01-01\n",
      "13  2025-02        246  1.748054e+10  7.105911e+07 2025-02-01\n",
      "14  2025-03        230  1.367924e+10  5.947496e+07 2025-03-01\n",
      "15  2025-04        208  1.116425e+10  5.367427e+07 2025-04-01\n",
      "16  2025-05        239  1.222680e+10  5.115814e+07 2025-05-01\n",
      "17  2025-06        234  1.337312e+10  5.715008e+07 2025-06-01\n",
      "18  2025-07        264  1.369923e+10  5.189101e+07 2025-07-01\n"
     ]
    }
   ],
   "source": [
    "df_filtered[\"Bulan\"] = df_filtered[\"Tanggal Pasien Masuk RS\"].dt.to_period(\"M\")\n",
    "\n",
    "monthly_agg = df_filtered.groupby(\"Bulan\").agg(\n",
    "    Frequency=(\"Claim ID\", \"nunique\"),\n",
    "    Total_Claim=(\"Nominal Klaim Yang Disetujui\", \"sum\")\n",
    ").reset_index()\n",
    "\n",
    "monthly_agg[\"Severity\"] = monthly_agg[\"Total_Claim\"] / monthly_agg[\"Frequency\"]\n",
    "monthly_agg[\"Bulan_Ts\"] = monthly_agg[\"Bulan\"].dt.to_timestamp()\n",
    "\n",
    "print(\"Historical Metrics:\")\n",
    "print(monthly_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c49020",
   "metadata": {},
   "source": [
    "## Tahap 8: Create Time Series Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d90a8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series objects created:\n",
      "Frequency series length: 19\n",
      "Total Claim series length: 19\n",
      "Severity series length: 19\n"
     ]
    }
   ],
   "source": [
    "ts_freq = TimeSeries.from_dataframe(monthly_agg, \"Bulan_Ts\", \"Frequency\")\n",
    "ts_total = TimeSeries.from_dataframe(monthly_agg, \"Bulan_Ts\", \"Total_Claim\")\n",
    "ts_sev = TimeSeries.from_dataframe(monthly_agg, \"Bulan_Ts\", \"Severity\")\n",
    "\n",
    "print(\"Time Series objects created:\")\n",
    "print(f\"Frequency series length: {len(ts_freq)}\")\n",
    "print(f\"Total Claim series length: {len(ts_total)}\")\n",
    "print(f\"Severity series length: {len(ts_sev)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1250bc29",
   "metadata": {},
   "source": [
    "## Tahap 9: Define Forecast Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5189d0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ GPU enabled: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n",
      "Model: amazon/chronos-2\n",
      "Input chunk length: 8 months\n",
      "Output chunk length: 5 months\n",
      "Min series length required: 13 months\n"
     ]
    }
   ],
   "source": [
    "# Chronos Model Setup dengan GPU Support\n",
    "model_name = \"amazon/chronos-2\"  \n",
    "input_chunk_length = 8  # Reduced from 12 for backtesting compatibility\n",
    "output_chunk_length = 5 # Forecast 5 months\n",
    "\n",
    "# GPU Configuration\n",
    "pl_trainer_kwargs = {}\n",
    "if torch.cuda.is_available():\n",
    "    pl_trainer_kwargs = {\n",
    "        \"accelerator\": \"gpu\",\n",
    "        \"devices\": [0],  # Use first GPU\n",
    "        \"precision\": 32   # Use float32 for stability\n",
    "    }\n",
    "    print(f\"âœ“ GPU enabled: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"GPU not available, using CPU\")\n",
    "\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Input chunk length: {input_chunk_length} months\")\n",
    "print(f\"Output chunk length: {output_chunk_length} months\")\n",
    "print(f\"Min series length required: {input_chunk_length + output_chunk_length} months\")\n",
    "\n",
    "def forecast_series(series, model_name, input_len, output_len, pl_trainer_kwargs):\n",
    "    model = Chronos2Model(\n",
    "        input_chunk_length=input_len,\n",
    "        output_chunk_length=output_len,\n",
    "        hub_model_name=model_name,\n",
    "        random_state=42,\n",
    "        pl_trainer_kwargs=pl_trainer_kwargs  # Pass GPU config here\n",
    "    )\n",
    "    \n",
    "    print(f\"Training model...\")\n",
    "    model.fit(series, verbose=True)\n",
    "    prediction = model.predict(output_len)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d24fe41",
   "metadata": {},
   "source": [
    "## Tahap 10: Forecast Claim Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6210b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasting Frequency...\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "ðŸ’¡ Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "ðŸ’¡ Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3050 Ti Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Frequency forecast completed\n"
     ]
    }
   ],
   "source": [
    "print(\"Forecasting Frequency...\")\n",
    "pred_freq = forecast_series(ts_freq, model_name, input_chunk_length, output_chunk_length, pl_trainer_kwargs)\n",
    "print(\"âœ“ Frequency forecast completed\")\n",
    "\n",
    "# Clear GPU cache if using CUDA\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27b2b43",
   "metadata": {},
   "source": [
    "## Tahap 11: Forecast Total Claim Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da9e8004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasting Total Claim...\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "ðŸ’¡ Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "ðŸ’¡ Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Total Claim forecast completed\n"
     ]
    }
   ],
   "source": [
    "print(\"Forecasting Total Claim...\")\n",
    "pred_total = forecast_series(ts_total, model_name, input_chunk_length, output_chunk_length, pl_trainer_kwargs)\n",
    "print(\"âœ“ Total Claim forecast completed\")\n",
    "\n",
    "# Clear GPU cache if using CUDA\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aef3fad",
   "metadata": {},
   "source": [
    "## Tahap 12: Forecast Claim Severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6aaede7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasting Severity...\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "ðŸ’¡ Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "ðŸ’¡ Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Severity forecast completed\n",
      "âœ“ GPU memory cleared\n"
     ]
    }
   ],
   "source": [
    "print(\"Forecasting Severity...\")\n",
    "pred_sev = forecast_series(ts_sev, model_name, input_chunk_length, output_chunk_length, pl_trainer_kwargs)\n",
    "print(\"âœ“ Severity forecast completed\")\n",
    "\n",
    "# Clear GPU cache if using CUDA\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"âœ“ GPU memory cleared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaa66a5",
   "metadata": {},
   "source": [
    "## Tahap 13: Model Evaluation (Backtesting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c80d1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ MAPE function defined\n"
     ]
    }
   ],
   "source": [
    "# Define MAPE function\n",
    "def calculate_mape(actual, predicted):\n",
    "    \"\"\"\n",
    "    Calculate Mean Absolute Percentage Error (MAPE)\n",
    "    \"\"\"\n",
    "    actual = np.array(actual).flatten()\n",
    "    predicted = np.array(predicted).flatten()\n",
    "    mask = actual != 0\n",
    "    mape = np.mean(np.abs((actual[mask] - predicted[mask]) / actual[mask])) * 100\n",
    "    return mape\n",
    "\n",
    "print(\"âœ“ MAPE function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ae04b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 2024-01 to 2025-02\n",
      "Test:  2025-03 to 2025-07\n"
     ]
    }
   ],
   "source": [
    "# Split data untuk backtesting (5 bulan terakhir = test set)\n",
    "train_size = len(monthly_agg) - 5\n",
    "test_size = 5\n",
    "\n",
    "monthly_train = monthly_agg.iloc[:train_size].copy()\n",
    "monthly_test = monthly_agg.iloc[train_size:].copy()\n",
    "\n",
    "print(f\"Train: {monthly_train['Bulan'].iloc[0]} to {monthly_train['Bulan'].iloc[-1]}\")\n",
    "print(f\"Test:  {monthly_test['Bulan'].iloc[0]} to {monthly_test['Bulan'].iloc[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49c9c665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Train time series created\n"
     ]
    }
   ],
   "source": [
    "# Create time series dari train data\n",
    "monthly_train['Bulan_Ts'] = monthly_train['Bulan'].dt.to_timestamp()\n",
    "\n",
    "ts_freq_train = TimeSeries.from_dataframe(monthly_train, \"Bulan_Ts\", \"Frequency\")\n",
    "ts_total_train = TimeSeries.from_dataframe(monthly_train, \"Bulan_Ts\", \"Total_Claim\")\n",
    "ts_sev_train = TimeSeries.from_dataframe(monthly_train, \"Bulan_Ts\", \"Severity\")\n",
    "\n",
    "print(\"âœ“ Train time series created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abb37671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "ðŸ’¡ Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "ðŸ’¡ Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "ðŸ’¡ Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "ðŸ’¡ Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "ðŸ’¡ Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "ðŸ’¡ Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Forecast test period\n",
    "pred_freq_test = forecast_series(ts_freq_train, model_name, input_chunk_length, test_size, pl_trainer_kwargs)\n",
    "pred_total_test = forecast_series(ts_total_train, model_name, input_chunk_length, test_size, pl_trainer_kwargs)\n",
    "pred_sev_test = forecast_series(ts_sev_train, model_name, input_chunk_length, test_size, pl_trainer_kwargs)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0757af90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODEL EVALUATION (Backtesting)\n",
      "============================================================\n",
      "âœ“ MAPE Frekuensi:   6.48%\n",
      "âœ“ MAPE Severitas:   6.03%\n",
      "âœ“ MAPE Total:       9.75%\n",
      "------------------------------------------------------------\n",
      "âœ“ Rata-rata MAPE:   7.42%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Calculate MAPE\n",
    "actual_freq = monthly_test['Frequency'].values\n",
    "predicted_freq = pred_freq_test.values().flatten()\n",
    "mape_frequency = calculate_mape(actual_freq, predicted_freq)\n",
    "\n",
    "actual_total = monthly_test['Total_Claim'].values\n",
    "predicted_total = pred_total_test.values().flatten()\n",
    "mape_total = calculate_mape(actual_total, predicted_total)\n",
    "\n",
    "actual_severity = monthly_test['Severity'].values\n",
    "predicted_severity = pred_sev_test.values().flatten()\n",
    "mape_severity = calculate_mape(actual_severity, predicted_severity)\n",
    "\n",
    "avg_mape = np.mean([mape_frequency, mape_severity, mape_total])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL EVALUATION (Backtesting)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"âœ“ MAPE Frekuensi:   {mape_frequency:.2f}%\")\n",
    "print(f\"âœ“ MAPE Severitas:   {mape_severity:.2f}%\")\n",
    "print(f\"âœ“ MAPE Total:       {mape_total:.2f}%\")\n",
    "print(\"-\"*60)\n",
    "print(f\"âœ“ Rata-rata MAPE:   {avg_mape:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5c2c99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Submission DataFrame shape: (15, 2)\n",
      "                         id         value\n",
      "0   2025_08_Claim_Frequency  2.472533e+02\n",
      "1    2025_08_Claim_Severity  5.244938e+07\n",
      "2       2025_08_Total_Claim  1.328346e+10\n",
      "3   2025_09_Claim_Frequency  2.449465e+02\n",
      "4    2025_09_Claim_Severity  5.282429e+07\n",
      "5       2025_09_Total_Claim  1.322625e+10\n",
      "6   2025_10_Claim_Frequency  2.438276e+02\n",
      "7    2025_10_Claim_Severity  5.289457e+07\n",
      "8       2025_10_Total_Claim  1.321587e+10\n",
      "9   2025_11_Claim_Frequency  2.429576e+02\n",
      "10   2025_11_Claim_Severity  5.283902e+07\n",
      "11      2025_11_Total_Claim  1.312850e+10\n",
      "12  2025_12_Claim_Frequency  2.422160e+02\n",
      "13   2025_12_Claim_Severity  5.269962e+07\n",
      "14      2025_12_Total_Claim  1.305097e+10\n"
     ]
    }
   ],
   "source": [
    "submission_list = []\n",
    "forecast_dates = pd.date_range(start=\"2025-08-01\", periods=5, freq=\"MS\")\n",
    "\n",
    "# Gunakan pred_freq, pred_total, pred_sev dari Tahap 10-12\n",
    "freq_values = pred_freq.values()\n",
    "total_values = pred_total.values()\n",
    "sev_values = pred_sev.values()\n",
    "\n",
    "for i, date in enumerate(forecast_dates):\n",
    "    date_str = date.strftime(\"%Y_%m\")\n",
    "    \n",
    "    submission_list.append({\n",
    "        \"id\": f\"{date_str}_Claim_Frequency\",\n",
    "        \"value\": freq_values[i][0]\n",
    "    })\n",
    "    \n",
    "    submission_list.append({\n",
    "        \"id\": f\"{date_str}_Claim_Severity\",\n",
    "        \"value\": sev_values[i][0]\n",
    "    })\n",
    "    \n",
    "    submission_list.append({\n",
    "        \"id\": f\"{date_str}_Total_Claim\",\n",
    "        \"value\": total_values[i][0]\n",
    "    })\n",
    "\n",
    "submission_df = pd.DataFrame(submission_list)\n",
    "\n",
    "print(f\"âœ“ Submission DataFrame shape: {submission_df.shape}\")\n",
    "print(submission_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff4c6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify rows\n",
    "if len(submission_df) != 15:\n",
    "    print(f\"Warning: Expected 15 rows, got {len(submission_df)}\")\n",
    "else:\n",
    "    print(\"âœ“ Submission has exactly 15 rows\")\n",
    "\n",
    "# Output\n",
    "output_path = \"../submission/submission_chronos2.csv\"\n",
    "submission_df.to_csv(output_path, index=False)\n",
    "print(f\"\\nâœ“ Submission saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df9b65c",
   "metadata": {},
   "source": [
    "## Tahap 16: MLForecast Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc14e8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for MLForecast (format: unique_id, ds, y)\n",
    "print(\"\\nPreparing data for MLForecast...\")\n",
    "\n",
    "df_mlforecast_freq = pd.DataFrame({\n",
    "    'unique_id': 'Frequency',\n",
    "    'ds': monthly_agg['Bulan_Ts'],\n",
    "    'y': monthly_agg['Frequency'].values\n",
    "})\n",
    "\n",
    "df_mlforecast_total = pd.DataFrame({\n",
    "    'unique_id': 'Total_Claim',\n",
    "    'ds': monthly_agg['Bulan_Ts'],\n",
    "    'y': monthly_agg['Total_Claim'].values\n",
    "})\n",
    "\n",
    "df_mlforecast_sev = pd.DataFrame({\n",
    "    'unique_id': 'Severity',\n",
    "    'ds': monthly_agg['Bulan_Ts'],\n",
    "    'y': monthly_agg['Severity'].values\n",
    "})\n",
    "\n",
    "# Combine all series\n",
    "df_mlforecast = pd.concat([df_mlforecast_freq, df_mlforecast_total, df_mlforecast_sev], ignore_index=True)\n",
    "\n",
    "print(\"Data shape for MLForecast:\", df_mlforecast.shape)\n",
    "print(df_mlforecast.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc03e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train MLForecast with multiple models\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING MLFORECAST MODELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initialize MLForecast dengan XGBoost\n",
    "fcst_xgb = MLForecast(\n",
    "    models=[\n",
    "        XGBRegressor(n_estimators=50, max_depth=5, learning_rate=0.1, random_state=42)\n",
    "    ],\n",
    "    freq='MS',  # Monthly start\n",
    "    lags=[1, 3, 6],  # Use previous 1, 3, 6 months\n",
    "    lag_transforms={\n",
    "        1: [('mean', 3), ('std', 3)]  # 3-month rolling mean & std\n",
    "    },\n",
    "    num_threads=1\n",
    ")\n",
    "\n",
    "print(\"Training XGBRegressor...\")\n",
    "fcst_xgb.fit(df_mlforecast)\n",
    "pred_mlforecast_xgb = fcst_xgb.predict(h=5, level=None)\n",
    "\n",
    "print(\"âœ“ XGBoost training completed\")\n",
    "print(\"\\nPredictions shape:\", pred_mlforecast_xgb.shape)\n",
    "print(pred_mlforecast_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029ec0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract predictions per metric\n",
    "pred_freq_mlf = pred_mlforecast_xgb[pred_mlforecast_xgb['unique_id'] == 'Frequency']['XGBRegressor'].values\n",
    "pred_total_mlf = pred_mlforecast_xgb[pred_mlforecast_xgb['unique_id'] == 'Total_Claim']['XGBRegressor'].values\n",
    "pred_sev_mlf = pred_mlforecast_xgb[pred_mlforecast_xgb['unique_id'] == 'Severity']['XGBRegressor'].values\n",
    "\n",
    "# Calculate MAPE for MLForecast\n",
    "mape_frequency_mlf = calculate_mape(actual_freq, pred_freq_mlf)\n",
    "mape_severity_mlf = calculate_mape(actual_severity, pred_sev_mlf)\n",
    "mape_total_mlf = calculate_mape(actual_total, pred_total_mlf)\n",
    "avg_mape_mlf = np.mean([mape_frequency_mlf, mape_severity_mlf, mape_total_mlf])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MLFORECAST EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"âœ“ MAPE Frekuensi:   {mape_frequency_mlf:.2f}%\")\n",
    "print(f\"âœ“ MAPE Severitas:   {mape_severity_mlf:.2f}%\")\n",
    "print(f\"âœ“ MAPE Total:       {mape_total_mlf:.2f}%\")\n",
    "print(\"-\"*60)\n",
    "print(f\"âœ“ Rata-rata MAPE:   {avg_mape_mlf:.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b428bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Chronos-2 vs MLForecast\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON: CHRONOS-2 vs MLFORECAST\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': ['Frequency', 'Severity', 'Total_Claim', 'Average'],\n",
    "    'Chronos-2 MAPE (%)': [\n",
    "        mape_frequency,\n",
    "        mape_severity,\n",
    "        mape_total,\n",
    "        avg_mape\n",
    "    ],\n",
    "    'MLForecast MAPE (%)': [\n",
    "        mape_frequency_mlf,\n",
    "        mape_severity_mlf,\n",
    "        mape_total_mlf,\n",
    "        avg_mape_mlf\n",
    "    ]\n",
    "})\n",
    "\n",
    "comparison_df['Difference (%)'] = comparison_df['Chronos-2 MAPE (%)'] - comparison_df['MLForecast MAPE (%)']\n",
    "comparison_df['Winner'] = comparison_df.apply(\n",
    "    lambda row: 'MLForecast' if row['Difference (%)'] > 0 else 'Chronos-2', \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Best model\n",
    "best_avg_mape = min(avg_mape, avg_mape_mlf)\n",
    "best_model = 'Chronos-2' if avg_mape < avg_mape_mlf else 'MLForecast'\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(f\"âœ“ BEST MODEL: {best_model} (MAPE: {best_avg_mape:.2f}%)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2e57bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi comparison\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. MAPE Comparison - Frequency\n",
    "ax = axes[0, 0]\n",
    "models = ['Chronos-2', 'MLForecast']\n",
    "freq_mapes = [mape_frequency, mape_frequency_mlf]\n",
    "colors = ['#1f77b4' if mape_frequency < mape_frequency_mlf else '#ff7f0e',\n",
    "          '#ff7f0e' if mape_frequency < mape_frequency_mlf else '#1f77b4']\n",
    "ax.bar(models, freq_mapes, color=colors)\n",
    "ax.set_ylabel('MAPE (%)', fontweight='bold')\n",
    "ax.set_title('Frequency MAPE Comparison', fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(freq_mapes):\n",
    "    ax.text(i, v + 0.5, f'{v:.2f}%', ha='center', fontweight='bold')\n",
    "\n",
    "# 2. MAPE Comparison - Severity\n",
    "ax = axes[0, 1]\n",
    "sev_mapes = [mape_severity, mape_severity_mlf]\n",
    "colors = ['#1f77b4' if mape_severity < mape_severity_mlf else '#ff7f0e',\n",
    "          '#ff7f0e' if mape_severity < mape_severity_mlf else '#1f77b4']\n",
    "ax.bar(models, sev_mapes, color=colors)\n",
    "ax.set_ylabel('MAPE (%)', fontweight='bold')\n",
    "ax.set_title('Severity MAPE Comparison', fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(sev_mapes):\n",
    "    ax.text(i, v + 0.5, f'{v:.2f}%', ha='center', fontweight='bold')\n",
    "\n",
    "# 3. MAPE Comparison - Total Claim\n",
    "ax = axes[1, 0]\n",
    "total_mapes = [mape_total, mape_total_mlf]\n",
    "colors = ['#1f77b4' if mape_total < mape_total_mlf else '#ff7f0e',\n",
    "          '#ff7f0e' if mape_total < mape_total_mlf else '#1f77b4']\n",
    "ax.bar(models, total_mapes, color=colors)\n",
    "ax.set_ylabel('MAPE (%)', fontweight='bold')\n",
    "ax.set_title('Total Claim MAPE Comparison', fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(total_mapes):\n",
    "    ax.text(i, v + 0.5, f'{v:.2f}%', ha='center', fontweight='bold')\n",
    "\n",
    "# 4. Average MAPE Comparison\n",
    "ax = axes[1, 1]\n",
    "avg_mapes = [avg_mape, avg_mape_mlf]\n",
    "colors = ['#2ca02c' if avg_mape < avg_mape_mlf else '#d62728',\n",
    "          '#d62728' if avg_mape < avg_mape_mlf else '#2ca02c']\n",
    "ax.bar(models, avg_mapes, color=colors, width=0.5)\n",
    "ax.set_ylabel('Average MAPE (%)', fontweight='bold')\n",
    "ax.set_title('Average MAPE Comparison (WINNER)', fontweight='bold', fontsize=12)\n",
    "ax.set_ylim(0, max(avg_mapes) * 1.2)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(avg_mapes):\n",
    "    ax.text(i, v + 0.5, f'{v:.2f}%', ha='center', fontweight='bold', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Comparison visualization completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
